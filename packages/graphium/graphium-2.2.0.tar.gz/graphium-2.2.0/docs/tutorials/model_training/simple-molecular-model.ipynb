{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training a simple model from configurations\n",
    "\n",
    "This tutorial will walk you through how to use a configuration file to define all the parameters of a model and of the trainer. This tutorial focuses on training from SMILES data in a CSV format.\n",
    "\n",
    "The work flow of testing your code on the entire pipeline is as follows:\n",
    "\n",
    "1. select a corresponding yaml file in the [expts/main_run_multitask.py](https://github.com/datamol-io/graphium/blob/master/expts/main_run_multitask.py) i.e. by `CONFIG_FILE = \"expts/configs/config_gps_10M_pcqm4m_mod.yaml\"`\n",
    "2. modify the yaml config file\n",
    "3. `python expts/main_run_multitask.py`\n",
    "\n",
    "There are multiple examples of YAML files located in the folder `graphium/expts/configs` that one can refer to when training a new model. The file `config_gps_10M_pcqm4m_mod.yaml` shows an example of running the GPS model on the pcqm4m dataset.\n",
    "\n",
    "## Creating the yaml file\n",
    "\n",
    "The first step is to create a YAML file containing all the required configurations, with an example given at `graphium/expts/config_gps_10M_pcqm4m_mod.yaml`. We will go through each part of the configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config_with_key(config, key):\n",
    "    new_config = {key: config[key]}\n",
    "    print(omegaconf.OmegaConf.to_yaml(new_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml file loaded\n"
     ]
    }
   ],
   "source": [
    "# First, let's read the yaml configuration file\n",
    "with open(\"../../../expts/configs/config_gps_10M_pcqm4m_mod.yaml\", \"r\") as file:\n",
    "    yaml_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "print(\"Yaml file loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "First, we define the constants such as the random seed and whether the model should raise or ignore an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constants:\n",
      "  name: pcqm4mv2_mpnn_4layer\n",
      "  seed: 42\n",
      "  raise_train_error: true\n",
      "  accelerator:\n",
      "    type: gpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"constants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodule\n",
    "\n",
    "Here, we define all the parameters required by the datamodule to run correctly, such as the dataset path, whether to cache, the columns for the training, the molecular featurization to use, the train/val/test splits and the batch size.\n",
    "\n",
    "For more details, see class [`MultitaskFromSmilesDataModule`](https://graphium-docs.datamol.io/stable/api/graphium.data.html#graphium.data.datamodule.MultitaskFromSmilesDataModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datamodule:\n",
      "  module_type: MultitaskFromSmilesDataModule\n",
      "  args:\n",
      "    task_specific_args:\n",
      "      homolumo:\n",
      "        df: null\n",
      "        task_level: graph\n",
      "        df_path: ~/scratch/data/graphium/data/PCQM4M/pcqm4mv2-20k.csv\n",
      "        smiles_col: cxsmiles\n",
      "        label_cols:\n",
      "        - homo_lumo_gap\n",
      "        split_val: 0.1\n",
      "        split_test: 0.1\n",
      "    prepare_dict_or_graph: pyg:graph\n",
      "    featurization_n_jobs: 30\n",
      "    featurization_progress: true\n",
      "    featurization_backend: loky\n",
      "    featurization:\n",
      "      mask_nan: 0\n",
      "      atom_property_list_onehot:\n",
      "      - atomic-number\n",
      "      - group\n",
      "      - period\n",
      "      - total-valence\n",
      "      atom_property_list_float:\n",
      "      - degree\n",
      "      - formal-charge\n",
      "      - radical-electron\n",
      "      - aromatic\n",
      "      - in-ring\n",
      "      edge_property_list:\n",
      "      - bond-type-onehot\n",
      "      - stereo\n",
      "      - in-ring\n",
      "      conformer_property_list:\n",
      "      - positions_3d\n",
      "      add_self_loop: false\n",
      "      explicit_H: false\n",
      "      use_bonds_weights: false\n",
      "      pos_encoding_as_features:\n",
      "        pos_types:\n",
      "          node_laplacian_eigvec:\n",
      "            pos_type: laplacian_eigvec\n",
      "            pos_level: node\n",
      "            num_pos: 8\n",
      "            normalization: none\n",
      "            disconnected_comp: true\n",
      "          node_laplacian_eigval:\n",
      "            pos_type: laplacian_eigval\n",
      "            pos_level: node\n",
      "            num_pos: 8\n",
      "            normalization: none\n",
      "            disconnected_comp: true\n",
      "          rw_return_probs:\n",
      "            pos_type: rw_return_probs\n",
      "            pos_level: node\n",
      "            ksteps:\n",
      "            - 4\n",
      "            - 8\n",
      "          nodepair_rw_transition_probs:\n",
      "            pos_type: rw_transition_probs\n",
      "            pos_level: edge\n",
      "            ksteps:\n",
      "            - 2\n",
      "            - 4\n",
      "          nodepair_rw_return_probs:\n",
      "            pos_type: rw_return_probs\n",
      "            pos_level: nodepair\n",
      "            ksteps:\n",
      "            - 4\n",
      "          electrostatic:\n",
      "            pos_type: electrostatic\n",
      "            pos_level: node\n",
      "          edge_commute:\n",
      "            pos_type: commute\n",
      "            pos_level: edge\n",
      "          nodepair_graphormer:\n",
      "            pos_type: graphormer\n",
      "            pos_level: nodepair\n",
      "    batch_size_training: 64\n",
      "    batch_size_inference: 16\n",
      "    num_workers: 0\n",
      "    persistent_workers: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"datamodule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "The architecture is based on [`FullGraphMultiTaskNetwork`](https://graphium-docs.datamol.io/stable/api/graphium.nn/architectures.html#graphium.nn.architectures.global_architectures.FullGraphMultiTaskNetwork).\n",
    "Here, we define all the layers for the model, including the layers for the pre-processing MLP (input layers `pre-nn` and `pre_nn_edges`), the positional encoder (`pe_encoders`), the post-processing MLP (output layers `post-nn`), and the main GNN (graph neural network `gnn`).\n",
    "\n",
    "You can find details in the following: \n",
    "- info about the positional encoder in [`graphium.nn.encoders`](https://graphium-docs.datamol.io/stable/api/graphium.nn/encoders.html)\n",
    "- info about the gnn layers in [`graphium.nn.pyg_layers`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html)\n",
    "- info about the architecture [`FullGraphMultiTaskNetwork`](https://graphium-docs.datamol.io/stable/api/graphium.nn/architectures.html#graphium.nn.architectures.global_architectures.FullGraphMultiTaskNetwork)\n",
    "- Main class for the GNN layers in [`BaseGraphStructure`](https://graphium-docs.datamol.io/stable/api/graphium.nn/graphium.nn.html#graphium.nn.base_graph_layer.BaseGraphStructure)\n",
    "\n",
    "The parameters allow to chose the feature size, the depth, the skip connections, the pooling and the virtual node. It also support different GNN layers such as [`GatedGCNPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gated_gcn_pyg), [`GINConvPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gin_pyg), [`GINEConvPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gin_pyg.GINEConvPyg), [`GPSLayerPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.gps_pyg.GPSLayerPyg), [`MPNNPlusPyg`](https://graphium-docs.datamol.io/stable/api/graphium.nn/pyg_layers.html#graphium.nn.pyg_layers.mpnn_pyg.MPNNPlusPyg).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\n",
      "  model_type: FullGraphMultiTaskNetwork\n",
      "  mup_base_path: null\n",
      "  pre_nn:\n",
      "    out_dim: 32\n",
      "    hidden_dims: 64\n",
      "    depth: 2\n",
      "    activation: relu\n",
      "    last_activation: none\n",
      "    dropout: 0.1\n",
      "    normalization: layer_norm\n",
      "    last_normalization: layer_norm\n",
      "    residual_type: none\n",
      "  pre_nn_edges:\n",
      "    out_dim: 16\n",
      "    hidden_dims: 32\n",
      "    depth: 2\n",
      "    activation: relu\n",
      "    last_activation: none\n",
      "    dropout: 0.1\n",
      "    normalization: layer_norm\n",
      "    last_normalization: layer_norm\n",
      "    residual_type: none\n",
      "  pe_encoders:\n",
      "    out_dim: 32\n",
      "    edge_out_dim: 16\n",
      "    pool: sum\n",
      "    last_norm: None\n",
      "    encoders:\n",
      "      emb_la_pos:\n",
      "        encoder_type: laplacian_pe\n",
      "        input_keys:\n",
      "        - laplacian_eigvec\n",
      "        - laplacian_eigval\n",
      "        output_keys:\n",
      "        - feat\n",
      "        hidden_dim: 32\n",
      "        model_type: DeepSet\n",
      "        num_layers: 2\n",
      "        num_layers_post: 1\n",
      "        dropout: 0.1\n",
      "        first_normalization: none\n",
      "      emb_rwse:\n",
      "        encoder_type: mlp\n",
      "        input_keys:\n",
      "        - rw_return_probs\n",
      "        output_keys:\n",
      "        - feat\n",
      "        hidden_dim: 32\n",
      "        num_layers: 2\n",
      "        dropout: 0.1\n",
      "        normalization: layer_norm\n",
      "        first_normalization: layer_norm\n",
      "      emb_electrostatic:\n",
      "        encoder_type: mlp\n",
      "        input_keys:\n",
      "        - electrostatic\n",
      "        output_keys:\n",
      "        - feat\n",
      "        hidden_dim: 32\n",
      "        num_layers: 1\n",
      "        dropout: 0.1\n",
      "        normalization: layer_norm\n",
      "        first_normalization: layer_norm\n",
      "      emb_edge_rwse:\n",
      "        encoder_type: mlp\n",
      "        input_keys:\n",
      "        - edge_rw_transition_probs\n",
      "        output_keys:\n",
      "        - edge_feat\n",
      "        hidden_dim: 32\n",
      "        num_layers: 1\n",
      "        dropout: 0.1\n",
      "        normalization: layer_norm\n",
      "      emb_edge_pes:\n",
      "        encoder_type: cat_mlp\n",
      "        input_keys:\n",
      "        - edge_rw_transition_probs\n",
      "        - edge_commute\n",
      "        output_keys:\n",
      "        - edge_feat\n",
      "        hidden_dim: 32\n",
      "        num_layers: 1\n",
      "        dropout: 0.1\n",
      "        normalization: layer_norm\n",
      "      gaussian_pos:\n",
      "        encoder_type: gaussian_kernel\n",
      "        input_keys:\n",
      "        - positions_3d\n",
      "        output_keys:\n",
      "        - feat\n",
      "        - nodepair_gaussian_bias_3d\n",
      "        num_heads: 2\n",
      "        num_layers: 2\n",
      "        embed_dim: 32\n",
      "        use_input_keys_prefix: false\n",
      "  gnn:\n",
      "    out_dim: 32\n",
      "    hidden_dims: 32\n",
      "    depth: 4\n",
      "    activation: gelu\n",
      "    last_activation: none\n",
      "    dropout: 0.0\n",
      "    normalization: layer_norm\n",
      "    last_normalization: layer_norm\n",
      "    residual_type: simple\n",
      "    pooling:\n",
      "    - sum\n",
      "    virtual_node: none\n",
      "    layer_type: pyg:gps\n",
      "    layer_kwargs:\n",
      "      node_residual: false\n",
      "      mpnn_type: pyg:mpnnplus\n",
      "      mpnn_kwargs:\n",
      "        in_dim: 32\n",
      "        out_dim: 32\n",
      "        in_dim_edges: 16\n",
      "        out_dim_edges: 16\n",
      "      attn_type: full-attention\n",
      "      attn_kwargs:\n",
      "        num_heads: 2\n",
      "      biased_attention_key: nodepair_gaussian_bias_3d\n",
      "  post_nn: null\n",
      "  task_heads:\n",
      "    homolumo:\n",
      "      out_dim: 1\n",
      "      hidden_dims: 256\n",
      "      depth: 2\n",
      "      activation: relu\n",
      "      last_activation: none\n",
      "      dropout: 0.1\n",
      "      normalization: layer_norm\n",
      "      last_normalization: none\n",
      "      residual_type: none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor\n",
    "\n",
    "In the predictor, we define the loss functions, the metrics to track on the progress bar, and all the parameters necessary for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor:\n",
      "  metrics_on_progress_bar:\n",
      "    homolumo:\n",
      "    - mae\n",
      "    - pearsonr\n",
      "  loss_fun:\n",
      "    homolumo: mse_ipu\n",
      "  random_seed: 42\n",
      "  optim_kwargs:\n",
      "    lr: 0.0004\n",
      "  torch_scheduler_kwargs:\n",
      "    module_type: WarmUpLinearLR\n",
      "    max_num_epochs: 5\n",
      "    warmup_epochs: 10\n",
      "    verbose: false\n",
      "  scheduler_kwargs: null\n",
      "  target_nan_mask: null\n",
      "  flag_kwargs:\n",
      "    n_steps: 0\n",
      "    alpha: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"predictor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "All the metrics can be defined there. If we want to use a classification metric, we can also define a threshold.\n",
    "\n",
    "See class [`graphium.trainer.metrics.MetricWrapper`](https://graphium-docs.datamol.io/stable/api/graphium.trainer.html#graphium.trainer.metrics.MetricWrapper) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics:\n",
      "  homolumo:\n",
      "  - name: mae\n",
      "    metric: mae_ipu\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: flatten\n",
      "    threshold_kwargs: null\n",
      "  - name: pearsonr\n",
      "    metric: pearsonr_ipu\n",
      "    threshold_kwargs: null\n",
      "    target_nan_mask: null\n",
      "    multitask_handling: mean-per-label\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "\n",
    "Finally, the Trainer defines the parameters for the number of epochs to train, the checkpoints, and the patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer:\n",
      "  logger:\n",
      "    save_dir: logs/PCQMv2\n",
      "    name: pcqm4mv2_mpnn_4layer\n",
      "    project: PCQMv2_mpnn\n",
      "  model_checkpoint:\n",
      "    dirpath: models_checkpoints/PCMQv2/\n",
      "    filename: pcqm4mv2_mpnn_4layer\n",
      "    save_top_k: 1\n",
      "    every_n_epochs: 100\n",
      "  trainer:\n",
      "    precision: 32\n",
      "    max_epochs: 5\n",
      "    min_epochs: 1\n",
      "    accumulate_grad_batches: 2\n",
      "    check_val_every_n_epoch: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Now that we defined all the configuration files, we want to train the model. The steps are fairly easy using the config loaders, and are given below.\n",
    "\n",
    "First make sure the dataset file is downloaded. \n",
    "Using `config_gps_10M_pcqm4m.yaml` as an example, if the file at `df_path` in the config is downloaded.\n",
    "In this case, we need to download `pcqm4mv2-20k.csv` into the specified directory `graphium/data/PCQM4M/pcqm4mv2-20k.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$`python expts/main_run_multitask.py`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4a99d018a205fcbcc0480c84566beaebcb91b08d0414b39a842df533e2a1d25"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
