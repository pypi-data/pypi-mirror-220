Metadata-Version: 2.1
Name: Arvixgpt
Version: 0.0.0.3
Summary: Search for updated article on arXiv.org
Author: Ali Nemati and AI Team
Author-email: <Alinemati1983@gmail.com>
Keywords: python,pandas,numpy,request,PyPDF2
Classifier: Development Status :: 1 - Planning
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: Unix
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: Microsoft :: Windows
Classifier: License :: Free To Use But Restricted
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: pandas
Requires-Dist: PyPDF2
Requires-Dist: requests


# Arvixgpt



## Step 1:



run the python script ArXixLatestArticle.py



```python

python Arvixgpt.py

```



then, select Please select one or more prefix. This line of code helps you to

search the article by title, author, abstract, comment, journal reference,...



## Step 2:



```text

Please select one or more prefix codes:

Explanation: prefix

Title: ti

Author: au

Abstract: abs

Comment: co

Journal Reference: jr

Subject Category: cat

Report Number: rn

Id (use id_list instead): id

All of the above: all



Please enter one or more prefix codes (separated by a comma if more than one): ti,au



```



## Step 3:



````text



## Below is our output example for our Summary:



```text

Title:	A Comprehensive Overview of Large Language Models

Summary:

Large Language Models (LLMs) have shown excellent generalization capabilities

that have led to the development of numerous models. These models propose

various new architectures, tweaking existing architectures with refined

training strategies, increasing context length, using high-quality training

data, and increasing training time to outperform baselines. Analyzing new

developments is crucial for identifying changes that enhance training stability

and improve generalization in LLMs. This survey paper comprehensively analyses

the LLMs architectures and their categorization, training strategies, training

datasets, and performance evaluations and discusses future research directions.

Moreover, the paper also discusses the basic building blocks and concepts

behind LLMs, followed by a complete overview of LLMs, including their important

features and functions. Finally, the paper summarizes significant findings from

LLM research and consolidates essential architectural and training strategies

for developing advanced LLMs. Given the continuous advancements in LLMs, we

intend to regularly update this paper by incorporating new sections and

featuring the latest LLM models.



PDF URL:	http://arxiv.org/pdf/2307.06435v1

Authors:	[arxiv.Result.Author('Humza Naveed'), arxiv.Result.Author('Asad Ullah Khan'), arxiv.Result.Author('Shi Qiu'), arxiv.Result.Author('Muhammad Saqib'), arxiv.Result.Author('Saeed Anwar'), arxiv.Result.Author('Muhammad Usman'), arxiv.Result.Author('Nick Barnes'), arxiv.Result.Author('Ajmal Mian')]

````

