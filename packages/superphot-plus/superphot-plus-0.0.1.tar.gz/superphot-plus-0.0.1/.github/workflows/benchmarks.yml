# This workflow will monitor code performance on the main branch.

name: Benchmark runtime and memory usage

on:
  push:
    branches: [ main ]

permissions:
  contents: write
  deployments: write

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: Install dependencies
      run: |
        sudo apt-get update
        python -m pip install --upgrade pip
        pip install .
        pip install .[dev]
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Run benchmarks with pytest and monitor plugin
      run: |
        pytest benchmarks/ \
          --parametrization-explicit \
          --db benchmarks/results.db
    - name: Extract relevant metrics
      run: |
        sqlite3 benchmarks/results.db \
          '.mode json' \
          '.once benchmarks/results.json' \
          'SELECT ITEM_PATH, ITEM, TOTAL_TIME, MEM_USAGE FROM TEST_METRICS'
        python benchmarks/preprocess_bench.py
    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: SUPERHOT-PLUS Benchmarking Monitor
        # Using a custom benchmark strategy, where the smaller the value the better
        tool: 'customSmallerIsBetter' 
        output-file-path: benchmarks/results.json
        gh-pages-branch: gh-pages
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        # Show alert with commit comment on detecting possible performance regression
        comment-on-alert: true
        alert-threshold: '200%'
        fail-on-alert: true