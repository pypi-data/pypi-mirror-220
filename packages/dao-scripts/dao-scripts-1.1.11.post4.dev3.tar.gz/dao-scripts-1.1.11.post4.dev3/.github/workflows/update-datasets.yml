name: Update datawarehouse datasets
on:
  schedule:
  - cron: "42 0 * * *"
  workflow_dispatch:
jobs:
  update_dw:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    - name: Install dao-scripts
      run: pip install dao-scripts
    - name: Get datawarehouse cache
      id: restore-cache
      uses: actions/cache/restore@v3
      with:
        path: datawarehouse
        key: ${{ runner.os }}-datawarehouse
    - name: Get cache info
      if: steps.restore-cache.outputs.cache-hit =='true'
      run: cat datawarehouse/update_date.txt datawarehouse/version.txt
    - name: Obtain datawarehouse
      run: dao-scripts --skip-token-balances
    - name: Upload datawarehouse cache
      uses: actions/cache/save@v3
      with:
        path: datawarehouse
        key: ${{ steps.restore-cache.outputs.cache-primary-key }}
    - name: Upload artifact
      uses: actions/upload-artifact@v3
      with:
        name: datawarehouse
        path: ./datawarehouse/
  upload_dw:
    runs-on: ubuntu-latest
    environment: daviddavo
    needs: [update_dw]
    steps:
    - name: Download artifact
      uses: actions/download-artifact@v3
      with:
        name: datawarehouse
        path: ./datawarehouse/
    - uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    - name: Install dao-scripts
      run: pip install dao-scripts[upload]
    - name: Upload dataset
      run: dao-utils-upload-dw
      env:
        KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
        KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        ZENODO_DEPOSITION_ID: ${{ secrets.ZENODO_DEPOSITION_ID }}
        ZENODO_API_TOKEN: ${{ secrets.ZENODO_API_TOKEN }}
